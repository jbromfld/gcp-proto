# Docker Compose for RAG Knowledge Search System - Development Setup
version: '3.8'

services:
  # Elasticsearch for vector storage
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: rag-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"  # Reduced memory for local dev
      - cluster.name=rag-cluster
      - node.name=rag-single-node
    ports:
      - "9200:9200"
    volumes:
      - es-data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/_cluster/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - rag-network

  # FastAPI backend with hot-reload
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
      target: development
    container_name: rag-api
    command: uvicorn rag_api:app --host 0.0.0.0 --port 8000 --reload
    volumes:
      - .:/app
    ports:
      - "8000:8000"
    environment:
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
      - LLM_PROVIDER=local
      - LLM_HOST=http://ollama:11434
      - EMBEDDING_PROVIDER=local
      - PYTHONPATH=/app
    depends_on:
      elasticsearch:
        condition: service_healthy
      ollama:
        condition: service_started
    networks:
      - rag-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Streamlit UI with hot-reload
  ui:
    build:
      context: .
      dockerfile: Dockerfile.ui
      target: development
    container_name: rag-ui
    command: streamlit run rag_ui.py --server.port 8501 --server.address 0.0.0.0
    volumes:
      - .:/app
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://api:8000
      - PYTHONPATH=/app
    depends_on:
      - api
    networks:
      - rag-network

# Networks and volumes configuration
networks:
  rag-network:
    driver: bridge

volumes:
  es-data:
    driver: local
  ollama-data:
    driver: local
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: rag-api
    ports:
      - "8000:8000"
    environment:
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - OLLAMA_URL=http://ollama:11434
      - EMBEDDING_PROVIDER=local
      - LLM_PROVIDER=local
      # For cloud providers, set these:
      # - EMBEDDING_PROVIDER=vertex
      # - LLM_PROVIDER=vertex
      # - GOOGLE_PROJECT_ID=your-project-id
      # - GOOGLE_APPLICATION_CREDENTIALS=/app/credentials.json
    depends_on:
      elasticsearch:
        condition: service_healthy
      ollama:
        condition: service_started
    volumes:
      - ./credentials:/app/credentials:ro
    networks:
      - rag-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Streamlit UI
  ui:
    build:
      context: .
      dockerfile: Dockerfile.ui
    container_name: rag-ui
    ports:
      - "8501:8501"
    environment:
      - API_BASE_URL=http://api:8000
    depends_on:
      - api
    networks:
      - rag-network

  # ETL scheduler (runs in background)
  etl:
    build:
      context: .
      dockerfile: Dockerfile.etl
    container_name: rag-etl
    environment:
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - OLLAMA_URL=http://ollama:11434
      - EMBEDDING_PROVIDER=local
      - ETL_INTERVAL_HOURS=24
      - SCRAPE_URLS=https://docs.python.org/3/tutorial/,https://fastapi.tiangolo.com/
    depends_on:
      elasticsearch:
        condition: service_healthy
      ollama:
        condition: service_started
    networks:
      - rag-network
    restart: unless-stopped

volumes:
  es-data:
    driver: local
  ollama-data:
    driver: local

networks:
  rag-network:
    driver: bridge